{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.load('../mount/Data_Manipulation_datasets/processed_X.npy')\n",
    "Y = np.load('../mount/Data_Manipulation_datasets/processed_Y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m7,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m132\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m10\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,078</span> (47.18 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,078\u001b[0m (47.18 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,078</span> (47.18 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,078\u001b[0m (47.18 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.Input(shape=(60,)),\n",
    "    tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "    tf.keras.layers.Dense(32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "    tf.keras.layers.Dense(4, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "    tf.keras.layers.Dense(2, activation='sigmoid', kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "model.compile(optimizer='adam', \n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(), \n",
    "              metrics=[ 'accuracy', tf.keras.metrics.Precision(class_id=0), tf.keras.metrics.Recall(class_id=0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "742/742 - 6s - 8ms/step - accuracy: 0.9060 - loss: 0.4671 - precision: 0.8571 - recall: 0.0757 - val_accuracy: 0.9123 - val_loss: 0.2648 - val_precision: 0.8731 - val_recall: 0.0747\n",
      "Epoch 2/50\n",
      "742/742 - 4s - 6ms/step - accuracy: 0.9108 - loss: 0.2611 - precision: 0.8593 - recall: 0.0687 - val_accuracy: 0.9140 - val_loss: 0.2524 - val_precision: 0.8696 - val_recall: 0.0928\n",
      "Epoch 3/50\n",
      "742/742 - 1s - 2ms/step - accuracy: 0.9099 - loss: 0.2547 - precision: 0.8792 - recall: 0.0723 - val_accuracy: 0.9098 - val_loss: 0.2512 - val_precision: 0.8657 - val_recall: 0.0688\n",
      "Epoch 4/50\n",
      "742/742 - 2s - 2ms/step - accuracy: 0.9101 - loss: 0.2532 - precision: 0.8796 - recall: 0.0719 - val_accuracy: 0.9110 - val_loss: 0.2474 - val_precision: 0.8745 - val_recall: 0.0837\n",
      "Epoch 5/50\n",
      "742/742 - 2s - 2ms/step - accuracy: 0.9096 - loss: 0.2516 - precision: 0.8756 - recall: 0.0726 - val_accuracy: 0.9115 - val_loss: 0.2458 - val_precision: 0.8676 - val_recall: 0.0675\n",
      "Epoch 6/50\n",
      "742/742 - 2s - 2ms/step - accuracy: 0.9098 - loss: 0.2509 - precision: 0.8746 - recall: 0.0690 - val_accuracy: 0.9138 - val_loss: 0.2450 - val_precision: 0.8711 - val_recall: 0.0798\n",
      "Epoch 7/50\n",
      "742/742 - 2s - 2ms/step - accuracy: 0.9095 - loss: 0.2499 - precision: 0.8757 - recall: 0.0726 - val_accuracy: 0.9115 - val_loss: 0.2461 - val_precision: 0.8742 - val_recall: 0.0530\n",
      "Epoch 8/50\n",
      "742/742 - 1s - 2ms/step - accuracy: 0.9104 - loss: 0.2499 - precision: 0.8692 - recall: 0.0697 - val_accuracy: 0.9105 - val_loss: 0.2474 - val_precision: 0.8715 - val_recall: 0.0762\n",
      "Epoch 9/50\n",
      "742/742 - 1s - 1ms/step - accuracy: 0.9103 - loss: 0.2496 - precision: 0.8760 - recall: 0.0716 - val_accuracy: 0.9113 - val_loss: 0.2462 - val_precision: 0.8700 - val_recall: 0.0753\n",
      "Epoch 10/50\n",
      "742/742 - 1s - 1ms/step - accuracy: 0.9103 - loss: 0.2495 - precision: 0.8668 - recall: 0.0706 - val_accuracy: 0.9121 - val_loss: 0.2447 - val_precision: 0.8728 - val_recall: 0.0667\n",
      "Epoch 11/50\n",
      "742/742 - 1s - 1ms/step - accuracy: 0.9104 - loss: 0.2495 - precision: 0.8903 - recall: 0.0712 - val_accuracy: 0.9120 - val_loss: 0.2445 - val_precision: 0.8708 - val_recall: 0.0539\n",
      "Epoch 12/50\n",
      "742/742 - 1s - 1ms/step - accuracy: 0.9101 - loss: 0.2491 - precision: 0.8884 - recall: 0.0699 - val_accuracy: 0.9120 - val_loss: 0.2451 - val_precision: 0.8685 - val_recall: 0.0768\n",
      "Epoch 13/50\n",
      "742/742 - 1s - 2ms/step - accuracy: 0.9112 - loss: 0.2487 - precision: 0.8794 - recall: 0.0694 - val_accuracy: 0.9116 - val_loss: 0.2444 - val_precision: 0.8711 - val_recall: 0.0631\n",
      "Epoch 14/50\n",
      "742/742 - 1s - 1ms/step - accuracy: 0.9120 - loss: 0.2483 - precision: 0.8791 - recall: 0.0687 - val_accuracy: 0.9140 - val_loss: 0.2440 - val_precision: 0.8679 - val_recall: 0.0814\n",
      "Epoch 15/50\n",
      "742/742 - 1s - 1ms/step - accuracy: 0.9114 - loss: 0.2485 - precision: 0.8581 - recall: 0.0692 - val_accuracy: 0.9116 - val_loss: 0.2445 - val_precision: 0.8761 - val_recall: 0.0795\n",
      "Epoch 16/50\n",
      "742/742 - 1s - 1ms/step - accuracy: 0.9103 - loss: 0.2487 - precision: 0.9021 - recall: 0.0719 - val_accuracy: 0.9103 - val_loss: 0.2433 - val_precision: 0.8762 - val_recall: 0.0675\n",
      "Epoch 17/50\n",
      "742/742 - 1s - 1ms/step - accuracy: 0.9107 - loss: 0.2487 - precision: 0.8694 - recall: 0.0695 - val_accuracy: 0.9142 - val_loss: 0.2490 - val_precision: 0.8719 - val_recall: 0.0947\n",
      "Epoch 18/50\n",
      "742/742 - 1s - 1ms/step - accuracy: 0.9100 - loss: 0.2484 - precision: 0.8740 - recall: 0.0694 - val_accuracy: 0.9132 - val_loss: 0.2439 - val_precision: 0.8605 - val_recall: 0.0635\n",
      "Epoch 19/50\n",
      "742/742 - 1s - 2ms/step - accuracy: 0.9113 - loss: 0.2481 - precision: 0.8778 - recall: 0.0689 - val_accuracy: 0.9108 - val_loss: 0.2433 - val_precision: 0.8747 - val_recall: 0.0625\n",
      "Epoch 20/50\n",
      "742/742 - 1s - 1ms/step - accuracy: 0.9112 - loss: 0.2484 - precision: 0.8753 - recall: 0.0701 - val_accuracy: 0.9132 - val_loss: 0.2433 - val_precision: 0.8698 - val_recall: 0.0751\n",
      "Epoch 21/50\n",
      "742/742 - 1s - 2ms/step - accuracy: 0.9097 - loss: 0.2476 - precision: 0.8916 - recall: 0.0700 - val_accuracy: 0.9130 - val_loss: 0.2452 - val_precision: 0.8675 - val_recall: 0.0823\n",
      "Epoch 22/50\n",
      "742/742 - 1s - 1ms/step - accuracy: 0.9103 - loss: 0.2479 - precision: 0.8574 - recall: 0.0697 - val_accuracy: 0.9121 - val_loss: 0.2439 - val_precision: 0.8677 - val_recall: 0.0650\n",
      "Epoch 23/50\n",
      "742/742 - 1s - 1ms/step - accuracy: 0.9103 - loss: 0.2484 - precision: 0.8879 - recall: 0.0698 - val_accuracy: 0.9108 - val_loss: 0.2438 - val_precision: 0.8696 - val_recall: 0.0724\n",
      "Epoch 24/50\n",
      "742/742 - 1s - 1ms/step - accuracy: 0.9104 - loss: 0.2478 - precision: 0.8627 - recall: 0.0680 - val_accuracy: 0.9103 - val_loss: 0.2431 - val_precision: 0.8846 - val_recall: 0.0657\n",
      "Epoch 25/50\n",
      "742/742 - 1s - 1ms/step - accuracy: 0.9104 - loss: 0.2478 - precision: 0.8822 - recall: 0.0673 - val_accuracy: 0.9133 - val_loss: 0.2424 - val_precision: 0.8731 - val_recall: 0.0655\n",
      "Epoch 26/50\n",
      "742/742 - 1s - 1ms/step - accuracy: 0.9113 - loss: 0.2477 - precision: 0.8619 - recall: 0.0673 - val_accuracy: 0.9147 - val_loss: 0.2430 - val_precision: 0.8665 - val_recall: 0.0730\n",
      "Epoch 27/50\n",
      "742/742 - 1s - 1ms/step - accuracy: 0.9104 - loss: 0.2482 - precision: 0.8565 - recall: 0.0690 - val_accuracy: 0.9110 - val_loss: 0.2446 - val_precision: 0.8719 - val_recall: 0.0804\n",
      "Epoch 28/50\n",
      "742/742 - 2s - 2ms/step - accuracy: 0.9118 - loss: 0.2478 - precision: 0.8860 - recall: 0.0691 - val_accuracy: 0.9123 - val_loss: 0.2440 - val_precision: 0.8699 - val_recall: 0.0892\n",
      "Epoch 29/50\n",
      "742/742 - 1s - 2ms/step - accuracy: 0.9100 - loss: 0.2483 - precision: 0.8792 - recall: 0.0702 - val_accuracy: 0.9132 - val_loss: 0.2426 - val_precision: 0.8629 - val_recall: 0.0696\n",
      "Epoch 30/50\n",
      "742/742 - 1s - 1ms/step - accuracy: 0.9112 - loss: 0.2470 - precision: 0.8478 - recall: 0.0686 - val_accuracy: 0.9123 - val_loss: 0.2440 - val_precision: 0.8653 - val_recall: 0.0722\n",
      "Epoch 31/50\n",
      "742/742 - 1s - 2ms/step - accuracy: 0.9096 - loss: 0.2478 - precision: 0.8669 - recall: 0.0665 - val_accuracy: 0.9128 - val_loss: 0.2440 - val_precision: 0.8680 - val_recall: 0.0852\n",
      "Epoch 32/50\n",
      "742/742 - 1s - 1ms/step - accuracy: 0.9102 - loss: 0.2477 - precision: 0.8632 - recall: 0.0691 - val_accuracy: 0.9130 - val_loss: 0.2421 - val_precision: 0.8770 - val_recall: 0.0612\n",
      "Epoch 33/50\n",
      "742/742 - 1s - 1ms/step - accuracy: 0.9109 - loss: 0.2476 - precision: 0.8569 - recall: 0.0665 - val_accuracy: 0.9108 - val_loss: 0.2437 - val_precision: 0.8651 - val_recall: 0.0648\n",
      "Epoch 34/50\n",
      "742/742 - 1s - 1ms/step - accuracy: 0.9106 - loss: 0.2473 - precision: 0.8677 - recall: 0.0672 - val_accuracy: 0.9135 - val_loss: 0.2428 - val_precision: 0.8712 - val_recall: 0.0812\n",
      "Epoch 35/50\n",
      "742/742 - 1s - 1ms/step - accuracy: 0.9104 - loss: 0.2473 - precision: 0.8480 - recall: 0.0679 - val_accuracy: 0.9120 - val_loss: 0.2423 - val_precision: 0.8664 - val_recall: 0.0716\n",
      "Epoch 36/50\n",
      "742/742 - 1s - 1ms/step - accuracy: 0.9109 - loss: 0.2472 - precision: 0.8801 - recall: 0.0711 - val_accuracy: 0.9115 - val_loss: 0.2437 - val_precision: 0.8694 - val_recall: 0.0697\n",
      "Epoch 37/50\n",
      "742/742 - 1s - 1ms/step - accuracy: 0.9108 - loss: 0.2476 - precision: 0.8966 - recall: 0.0698 - val_accuracy: 0.9116 - val_loss: 0.2430 - val_precision: 0.8802 - val_recall: 0.0644\n",
      "Epoch 38/50\n",
      "742/742 - 1s - 1ms/step - accuracy: 0.9119 - loss: 0.2477 - precision: 0.9097 - recall: 0.0711 - val_accuracy: 0.9126 - val_loss: 0.2427 - val_precision: 0.8708 - val_recall: 0.0783\n",
      "Epoch 39/50\n",
      "742/742 - 1s - 1ms/step - accuracy: 0.9112 - loss: 0.2470 - precision: 0.8761 - recall: 0.0690 - val_accuracy: 0.9120 - val_loss: 0.2435 - val_precision: 0.8722 - val_recall: 0.0585\n",
      "Epoch 40/50\n",
      "742/742 - 1s - 1ms/step - accuracy: 0.9107 - loss: 0.2472 - precision: 0.8676 - recall: 0.0676 - val_accuracy: 0.9128 - val_loss: 0.2421 - val_precision: 0.8633 - val_recall: 0.0686\n",
      "Epoch 41/50\n",
      "742/742 - 1s - 1ms/step - accuracy: 0.9113 - loss: 0.2470 - precision: 0.8923 - recall: 0.0703 - val_accuracy: 0.9133 - val_loss: 0.2423 - val_precision: 0.8774 - val_recall: 0.0696\n",
      "Epoch 42/50\n",
      "742/742 - 1s - 1ms/step - accuracy: 0.9107 - loss: 0.2475 - precision: 0.8665 - recall: 0.0682 - val_accuracy: 0.9125 - val_loss: 0.2432 - val_precision: 0.8669 - val_recall: 0.0795\n",
      "Epoch 43/50\n",
      "742/742 - 1s - 1ms/step - accuracy: 0.9110 - loss: 0.2473 - precision: 0.8921 - recall: 0.0682 - val_accuracy: 0.9108 - val_loss: 0.2424 - val_precision: 0.8713 - val_recall: 0.0619\n",
      "Epoch 44/50\n",
      "742/742 - 1s - 1ms/step - accuracy: 0.9106 - loss: 0.2469 - precision: 0.8694 - recall: 0.0675 - val_accuracy: 0.9125 - val_loss: 0.2434 - val_precision: 0.8691 - val_recall: 0.0810\n",
      "Epoch 45/50\n",
      "742/742 - 1s - 1ms/step - accuracy: 0.9112 - loss: 0.2473 - precision: 0.8563 - recall: 0.0687 - val_accuracy: 0.9120 - val_loss: 0.2427 - val_precision: 0.8607 - val_recall: 0.0659\n",
      "Epoch 46/50\n",
      "742/742 - 1s - 2ms/step - accuracy: 0.9105 - loss: 0.2473 - precision: 0.8724 - recall: 0.0684 - val_accuracy: 0.9130 - val_loss: 0.2429 - val_precision: 0.8714 - val_recall: 0.0697\n",
      "Epoch 47/50\n",
      "742/742 - 1s - 1ms/step - accuracy: 0.9120 - loss: 0.2469 - precision: 0.8817 - recall: 0.0680 - val_accuracy: 0.9133 - val_loss: 0.2502 - val_precision: 0.8692 - val_recall: 0.0924\n",
      "Epoch 48/50\n",
      "742/742 - 1s - 2ms/step - accuracy: 0.9103 - loss: 0.2473 - precision: 0.8690 - recall: 0.0687 - val_accuracy: 0.9123 - val_loss: 0.2440 - val_precision: 0.8627 - val_recall: 0.0766\n",
      "Epoch 49/50\n",
      "742/742 - 1s - 2ms/step - accuracy: 0.9114 - loss: 0.2471 - precision: 0.8969 - recall: 0.0687 - val_accuracy: 0.9118 - val_loss: 0.2473 - val_precision: 0.8703 - val_recall: 0.0934\n",
      "Epoch 50/50\n",
      "742/742 - 1s - 2ms/step - accuracy: 0.9105 - loss: 0.2473 - precision: 0.8555 - recall: 0.0696 - val_accuracy: 0.9110 - val_loss: 0.2419 - val_precision: 0.8699 - val_recall: 0.0650\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "epoch = 50 \n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1) \n",
    "\n",
    "history = model.fit(X_train, Y_train, \n",
    "                    epochs=epoch, \n",
    "                    validation_split=0.2,\n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### functions for running metric and saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, precision_recall_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def evaluation_metrics(Y, Y_pred, Y_prob, save_plots_dir=None):\n",
    "    tp, fn, fp, tn = confusion_matrix(Y, Y_pred).ravel()\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    accuracy = (tp + tn) / (tp + fn + fp + tn)\n",
    "    AUC = roc_auc_score(Y, Y_prob[:, 1])\n",
    "    \n",
    "    print(\"||>> Precision: \", precision)\n",
    "    print(\"||>> Recall: \", recall)\n",
    "    print(\"||>> F1: \", f1)\n",
    "    print(\"||>> Accuracy: \", accuracy)\n",
    "    print(\"||>> AUC: \", AUC)\n",
    "    \n",
    "    # ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(Y, Y_prob[:, 1])\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "    plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "    plt.title('ROC Curve')\n",
    "    if save_plots_dir:\n",
    "        plt.savefig(os.path.join(save_plots_dir, 'roc_curve.png'))\n",
    "    else:\n",
    "        plt.show()\n",
    "    \n",
    "    # Precision-Recall curve\n",
    "    precisions, recalls, thresholds = precision_recall_curve(Y, Y_prob[:, 0], pos_label=0)\n",
    "    plt.cla()\n",
    "    plt.plot(recalls, precisions)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall curve') \n",
    "    if save_plots_dir:\n",
    "        plt.savefig(os.path.join(save_plots_dir, 'precision_recall_curve.png'))\n",
    "    else:\n",
    "        plt.show()\n",
    "    \n",
    "    AUPRC = auc(recalls, precisions)\n",
    "    print(\"||>> AUPRC: \", AUPRC)\n",
    "    \n",
    "    return precision, recall, f1, accuracy, AUC, AUPRC\n",
    "\n",
    "\n",
    "def save_model_and_performance(model, X, Y, model_name, if_test_data_provided=False):\n",
    "    model_dir = os.path.join('../mount/trained_models', model_name)\n",
    "    os.makedirs(model_dir)\n",
    "    model.save('../mount/trained_models/{}/model.keras'.format(model_name))\n",
    "    \n",
    "    if if_test_data_provided:\n",
    "        X_test, Y_test = X, Y\n",
    "    else:\n",
    "        _, X_test, _, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "    \n",
    "    Y_prob = model.predict(X_test)\n",
    "    Y_pred = np.argmax(Y_prob, axis=1)\n",
    "    \n",
    "    precision, recall, f1, accuracy, AUC, AUPRC = evaluation_metrics(Y_test, Y_pred, Y_prob, save_plots_dir=model_dir)\n",
    "    with open(os.path.join(model_dir, 'metrics.txt'), 'w') as f:\n",
    "        f.write(\"Precision: {}\\n\".format(precision))\n",
    "        f.write(\"Recall: {}\\n\".format(recall))\n",
    "        f.write(\"F1: {}\\n\".format(f1))\n",
    "        f.write(\"Accuracy: {}\\n\".format(accuracy))\n",
    "        f.write(\"AUC: {}\\n\".format(AUC))\n",
    "        f.write(\"AUPRC: {}\\n\".format(AUPRC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### checking and saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "||>> Precision:  0.7631578947368421\n",
      "||>> Recall:  0.4027777777777778\n",
      "||>> F1:  0.5272727272727273\n",
      "||>> Accuracy:  0.921092564491654\n",
      "||>> AUC:  0.930200643573727\n",
      "||>> AUPRC:  0.632742475851821\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"NN_1\"\n",
    "save_model_and_performance(model, X_test, Y_test, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Take-away** : - Even NN is showing similar performance as the different ML models, slightly better than the XG-Boost model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach 2: Train the model with even number of samples from each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m7,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m132\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m10\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,078</span> (47.18 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,078\u001b[0m (47.18 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,078</span> (47.18 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,078\u001b[0m (47.18 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Same model architecture to be used \n",
    "import tensorflow as tf \n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.Input(shape=(60,)),\n",
    "    tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "    tf.keras.layers.Dense(32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "    tf.keras.layers.Dense(4, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "    tf.keras.layers.Dense(2, activation='sigmoid', kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(), \n",
    "              metrics=[ 'accuracy', tf.keras.metrics.Precision(class_id=0), tf.keras.metrics.Recall(class_id=0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 - 1s - 4ms/step - accuracy: 0.8946 - loss: 0.3565 - precision_2: 0.4344 - recall_2: 0.5697 - val_accuracy: 0.8191 - val_loss: 0.4630 - val_precision_2: 1.0000 - val_recall_2: 0.1763\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8307 - loss: 0.4330 - precision_2: 0.9141 - recall_2: 0.2603\n",
      "|| >> End of epoch 0 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8895 - loss: 0.3600 - precision_2: 0.3426 - recall_2: 0.5865 - val_accuracy: 0.8343 - val_loss: 0.4502 - val_precision_2: 1.0000 - val_recall_2: 0.1565\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8322 - loss: 0.4378 - precision_2: 0.9171 - recall_2: 0.2566\n",
      "|| >> End of epoch 1 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8870 - loss: 0.3659 - precision_2: 0.3816 - recall_2: 0.5676 - val_accuracy: 0.7964 - val_loss: 0.4963 - val_precision_2: 1.0000 - val_recall_2: 0.1976\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8245 - loss: 0.4430 - precision_2: 0.9177 - recall_2: 0.2651\n",
      "|| >> End of epoch 2 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8751 - loss: 0.3836 - precision_2: 0.4866 - recall_2: 0.5997 - val_accuracy: 0.8541 - val_loss: 0.3899 - val_precision_2: 1.0000 - val_recall_2: 0.1398\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8349 - loss: 0.4246 - precision_2: 0.9177 - recall_2: 0.2548\n",
      "|| >> End of epoch 3 << ||\n",
      "185/185 - 1s - 4ms/step - accuracy: 0.8873 - loss: 0.3605 - precision_2: 0.4302 - recall_2: 0.5826 - val_accuracy: 0.8647 - val_loss: 0.3799 - val_precision_2: 1.0000 - val_recall_2: 0.1337\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8642 - loss: 0.3816 - precision_2: 0.9135 - recall_2: 0.2184\n",
      "|| >> End of epoch 4 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8795 - loss: 0.3727 - precision_2: 0.4352 - recall_2: 0.5719 - val_accuracy: 0.8252 - val_loss: 0.4402 - val_precision_2: 1.0000 - val_recall_2: 0.1748\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8480 - loss: 0.4111 - precision_2: 0.9135 - recall_2: 0.2393\n",
      "|| >> End of epoch 5 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8856 - loss: 0.3659 - precision_2: 0.5280 - recall_2: 0.5781 - val_accuracy: 0.7872 - val_loss: 0.5099 - val_precision_2: 1.0000 - val_recall_2: 0.2067\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8233 - loss: 0.4612 - precision_2: 0.9191 - recall_2: 0.2702\n",
      "|| >> End of epoch 6 << ||\n",
      "185/185 - 1s - 4ms/step - accuracy: 0.8897 - loss: 0.3585 - precision_2: 0.4185 - recall_2: 0.5898 - val_accuracy: 0.8632 - val_loss: 0.3774 - val_precision_2: 1.0000 - val_recall_2: 0.1353\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8332 - loss: 0.4283 - precision_2: 0.9170 - recall_2: 0.2563\n",
      "|| >> End of epoch 7 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8826 - loss: 0.3725 - precision_2: 0.4353 - recall_2: 0.5750 - val_accuracy: 0.8207 - val_loss: 0.4475 - val_precision_2: 1.0000 - val_recall_2: 0.1733\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8209 - loss: 0.4548 - precision_2: 0.9173 - recall_2: 0.2705\n",
      "|| >> End of epoch 8 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8795 - loss: 0.3744 - precision_2: 0.4652 - recall_2: 0.5698 - val_accuracy: 0.8511 - val_loss: 0.4164 - val_precision_2: 1.0000 - val_recall_2: 0.1459\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8337 - loss: 0.4331 - precision_2: 0.9187 - recall_2: 0.2588\n",
      "|| >> End of epoch 9 << ||\n",
      "185/185 - 1s - 4ms/step - accuracy: 0.8834 - loss: 0.3646 - precision_2: 0.4611 - recall_2: 0.5742 - val_accuracy: 0.8359 - val_loss: 0.4402 - val_precision_2: 1.0000 - val_recall_2: 0.1596\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8376 - loss: 0.4262 - precision_2: 0.9160 - recall_2: 0.2538\n",
      "|| >> End of epoch 10 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8790 - loss: 0.3762 - precision_2: 0.4485 - recall_2: 0.5849 - val_accuracy: 0.8009 - val_loss: 0.5001 - val_precision_2: 1.0000 - val_recall_2: 0.1976\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8240 - loss: 0.4478 - precision_2: 0.9173 - recall_2: 0.2712\n",
      "|| >> End of epoch 11 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8868 - loss: 0.3608 - precision_2: 0.3868 - recall_2: 0.5859 - val_accuracy: 0.7872 - val_loss: 0.5198 - val_precision_2: 1.0000 - val_recall_2: 0.2097\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8111 - loss: 0.4851 - precision_2: 0.9162 - recall_2: 0.2862\n",
      "|| >> End of epoch 12 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8812 - loss: 0.3758 - precision_2: 0.4142 - recall_2: 0.5684 - val_accuracy: 0.8313 - val_loss: 0.4455 - val_precision_2: 1.0000 - val_recall_2: 0.1626\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8408 - loss: 0.4152 - precision_2: 0.9171 - recall_2: 0.2502\n",
      "|| >> End of epoch 13 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8883 - loss: 0.3590 - precision_2: 0.4732 - recall_2: 0.5916 - val_accuracy: 0.8313 - val_loss: 0.4509 - val_precision_2: 1.0000 - val_recall_2: 0.1672\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8379 - loss: 0.4182 - precision_2: 0.9194 - recall_2: 0.2519\n",
      "|| >> End of epoch 14 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8888 - loss: 0.3588 - precision_2: 0.4592 - recall_2: 0.5901 - val_accuracy: 0.8419 - val_loss: 0.3963 - val_precision_2: 1.0000 - val_recall_2: 0.1505\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8411 - loss: 0.4084 - precision_2: 0.9171 - recall_2: 0.2442\n",
      "|| >> End of epoch 15 << ||\n",
      "185/185 - 0s - 2ms/step - accuracy: 0.8822 - loss: 0.3636 - precision_2: 0.4090 - recall_2: 0.5888 - val_accuracy: 0.8450 - val_loss: 0.4141 - val_precision_2: 1.0000 - val_recall_2: 0.1535\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8453 - loss: 0.4104 - precision_2: 0.9158 - recall_2: 0.2453\n",
      "|| >> End of epoch 16 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8827 - loss: 0.3703 - precision_2: 0.4082 - recall_2: 0.5950 - val_accuracy: 0.8465 - val_loss: 0.4011 - val_precision_2: 1.0000 - val_recall_2: 0.1505\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8563 - loss: 0.3927 - precision_2: 0.9110 - recall_2: 0.2286\n",
      "|| >> End of epoch 17 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8880 - loss: 0.3574 - precision_2: 0.4059 - recall_2: 0.5847 - val_accuracy: 0.8161 - val_loss: 0.4341 - val_precision_2: 1.0000 - val_recall_2: 0.1793\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8255 - loss: 0.4559 - precision_2: 0.9187 - recall_2: 0.2685\n",
      "|| >> End of epoch 18 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8866 - loss: 0.3608 - precision_2: 0.4271 - recall_2: 0.5728 - val_accuracy: 0.8328 - val_loss: 0.4179 - val_precision_2: 1.0000 - val_recall_2: 0.1657\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8412 - loss: 0.4134 - precision_2: 0.9135 - recall_2: 0.2483\n",
      "|| >> End of epoch 19 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8868 - loss: 0.3594 - precision_2: 0.4343 - recall_2: 0.5712 - val_accuracy: 0.8055 - val_loss: 0.4903 - val_precision_2: 1.0000 - val_recall_2: 0.1930\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8305 - loss: 0.4361 - precision_2: 0.9151 - recall_2: 0.2625\n",
      "|| >> End of epoch 20 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8851 - loss: 0.3590 - precision_2: 0.4447 - recall_2: 0.5844 - val_accuracy: 0.7720 - val_loss: 0.5387 - val_precision_2: 1.0000 - val_recall_2: 0.2234\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8002 - loss: 0.4965 - precision_2: 0.9164 - recall_2: 0.2988\n",
      "|| >> End of epoch 21 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8817 - loss: 0.3712 - precision_2: 0.4780 - recall_2: 0.5941 - val_accuracy: 0.8131 - val_loss: 0.4682 - val_precision_2: 1.0000 - val_recall_2: 0.1854\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8343 - loss: 0.4251 - precision_2: 0.9187 - recall_2: 0.2569\n",
      "|| >> End of epoch 22 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8837 - loss: 0.3672 - precision_2: 0.3922 - recall_2: 0.5758 - val_accuracy: 0.8587 - val_loss: 0.3838 - val_precision_2: 1.0000 - val_recall_2: 0.1398\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8381 - loss: 0.4188 - precision_2: 0.9154 - recall_2: 0.2510\n",
      "|| >> End of epoch 23 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8924 - loss: 0.3556 - precision_2: 0.4803 - recall_2: 0.5817 - val_accuracy: 0.8450 - val_loss: 0.4235 - val_precision_2: 1.0000 - val_recall_2: 0.1535\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8283 - loss: 0.4413 - precision_2: 0.9185 - recall_2: 0.2626\n",
      "|| >> End of epoch 24 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8881 - loss: 0.3639 - precision_2: 0.4108 - recall_2: 0.5774 - val_accuracy: 0.8283 - val_loss: 0.4464 - val_precision_2: 1.0000 - val_recall_2: 0.1687\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8202 - loss: 0.4667 - precision_2: 0.9211 - recall_2: 0.2768\n",
      "|| >> End of epoch 25 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8890 - loss: 0.3587 - precision_2: 0.4410 - recall_2: 0.5785 - val_accuracy: 0.8450 - val_loss: 0.4287 - val_precision_2: 1.0000 - val_recall_2: 0.1550\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8403 - loss: 0.4191 - precision_2: 0.9147 - recall_2: 0.2459\n",
      "|| >> End of epoch 26 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8868 - loss: 0.3614 - precision_2: 0.4442 - recall_2: 0.5822 - val_accuracy: 0.7842 - val_loss: 0.5489 - val_precision_2: 1.0000 - val_recall_2: 0.2128\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8215 - loss: 0.4542 - precision_2: 0.9189 - recall_2: 0.2729\n",
      "|| >> End of epoch 27 << ||\n",
      "185/185 - 1s - 4ms/step - accuracy: 0.8854 - loss: 0.3637 - precision_2: 0.4363 - recall_2: 0.5741 - val_accuracy: 0.8419 - val_loss: 0.4229 - val_precision_2: 1.0000 - val_recall_2: 0.1535\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8573 - loss: 0.3795 - precision_2: 0.9169 - recall_2: 0.2295\n",
      "|| >> End of epoch 28 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8832 - loss: 0.3661 - precision_2: 0.4620 - recall_2: 0.5796 - val_accuracy: 0.8495 - val_loss: 0.4039 - val_precision_2: 1.0000 - val_recall_2: 0.1505\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8497 - loss: 0.4021 - precision_2: 0.9147 - recall_2: 0.2417\n",
      "|| >> End of epoch 29 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8866 - loss: 0.3613 - precision_2: 0.3781 - recall_2: 0.5703 - val_accuracy: 0.8024 - val_loss: 0.4891 - val_precision_2: 1.0000 - val_recall_2: 0.1930\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8278 - loss: 0.4440 - precision_2: 0.9203 - recall_2: 0.2688\n",
      "|| >> End of epoch 30 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8809 - loss: 0.3638 - precision_2: 0.4654 - recall_2: 0.5794 - val_accuracy: 0.8191 - val_loss: 0.4726 - val_precision_2: 1.0000 - val_recall_2: 0.1793\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8330 - loss: 0.4317 - precision_2: 0.9176 - recall_2: 0.2588\n",
      "|| >> End of epoch 31 << ||\n",
      "185/185 - 1s - 4ms/step - accuracy: 0.8841 - loss: 0.3640 - precision_2: 0.4912 - recall_2: 0.5860 - val_accuracy: 0.8207 - val_loss: 0.4391 - val_precision_2: 1.0000 - val_recall_2: 0.1717\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8414 - loss: 0.4295 - precision_2: 0.9161 - recall_2: 0.2498\n",
      "|| >> End of epoch 32 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8880 - loss: 0.3659 - precision_2: 0.4312 - recall_2: 0.5793 - val_accuracy: 0.8465 - val_loss: 0.3818 - val_precision_2: 1.0000 - val_recall_2: 0.1489\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8585 - loss: 0.3899 - precision_2: 0.9155 - recall_2: 0.2310\n",
      "|| >> End of epoch 33 << ||\n",
      "185/185 - 1s - 4ms/step - accuracy: 0.8800 - loss: 0.3694 - precision_2: 0.4542 - recall_2: 0.5890 - val_accuracy: 0.8374 - val_loss: 0.4122 - val_precision_2: 1.0000 - val_recall_2: 0.1611\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8392 - loss: 0.4075 - precision_2: 0.9195 - recall_2: 0.2518\n",
      "|| >> End of epoch 34 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8858 - loss: 0.3594 - precision_2: 0.4540 - recall_2: 0.5776 - val_accuracy: 0.8085 - val_loss: 0.5372 - val_precision_2: 1.0000 - val_recall_2: 0.1915\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8125 - loss: 0.4735 - precision_2: 0.9186 - recall_2: 0.2879\n",
      "|| >> End of epoch 35 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8861 - loss: 0.3557 - precision_2: 0.4745 - recall_2: 0.5902 - val_accuracy: 0.8252 - val_loss: 0.4421 - val_precision_2: 1.0000 - val_recall_2: 0.1733\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8200 - loss: 0.4636 - precision_2: 0.9173 - recall_2: 0.2752\n",
      "|| >> End of epoch 36 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8883 - loss: 0.3588 - precision_2: 0.4369 - recall_2: 0.5759 - val_accuracy: 0.8617 - val_loss: 0.3864 - val_precision_2: 1.0000 - val_recall_2: 0.1383\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8670 - loss: 0.3693 - precision_2: 0.9195 - recall_2: 0.2191\n",
      "|| >> End of epoch 37 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8920 - loss: 0.3512 - precision_2: 0.4507 - recall_2: 0.5794 - val_accuracy: 0.8100 - val_loss: 0.4735 - val_precision_2: 1.0000 - val_recall_2: 0.1900\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8298 - loss: 0.4446 - precision_2: 0.9157 - recall_2: 0.2617\n",
      "|| >> End of epoch 38 << ||\n",
      "185/185 - 1s - 4ms/step - accuracy: 0.8831 - loss: 0.3586 - precision_2: 0.4274 - recall_2: 0.5764 - val_accuracy: 0.8100 - val_loss: 0.4919 - val_precision_2: 1.0000 - val_recall_2: 0.1884\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8370 - loss: 0.4310 - precision_2: 0.9163 - recall_2: 0.2572\n",
      "|| >> End of epoch 39 << ||\n",
      "185/185 - 1s - 4ms/step - accuracy: 0.8807 - loss: 0.3717 - precision_2: 0.4225 - recall_2: 0.5950 - val_accuracy: 0.8663 - val_loss: 0.3735 - val_precision_2: 1.0000 - val_recall_2: 0.1322\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8648 - loss: 0.3793 - precision_2: 0.9185 - recall_2: 0.2212\n",
      "|| >> End of epoch 40 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8836 - loss: 0.3654 - precision_2: 0.4194 - recall_2: 0.5762 - val_accuracy: 0.8663 - val_loss: 0.3933 - val_precision_2: 1.0000 - val_recall_2: 0.1337\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8437 - loss: 0.4236 - precision_2: 0.9145 - recall_2: 0.2484\n",
      "|| >> End of epoch 41 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8861 - loss: 0.3528 - precision_2: 0.4049 - recall_2: 0.5771 - val_accuracy: 0.8207 - val_loss: 0.4715 - val_precision_2: 1.0000 - val_recall_2: 0.1763\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8165 - loss: 0.4654 - precision_2: 0.9188 - recall_2: 0.2799\n",
      "|| >> End of epoch 42 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8827 - loss: 0.3701 - precision_2: 0.4523 - recall_2: 0.5690 - val_accuracy: 0.8313 - val_loss: 0.4151 - val_precision_2: 1.0000 - val_recall_2: 0.1687\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8307 - loss: 0.4306 - precision_2: 0.9167 - recall_2: 0.2651\n",
      "|| >> End of epoch 43 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8841 - loss: 0.3645 - precision_2: 0.4199 - recall_2: 0.5839 - val_accuracy: 0.8465 - val_loss: 0.3950 - val_precision_2: 1.0000 - val_recall_2: 0.1489\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8455 - loss: 0.3984 - precision_2: 0.9150 - recall_2: 0.2433\n",
      "|| >> End of epoch 44 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8900 - loss: 0.3560 - precision_2: 0.4507 - recall_2: 0.5904 - val_accuracy: 0.8207 - val_loss: 0.4612 - val_precision_2: 1.0000 - val_recall_2: 0.1793\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8237 - loss: 0.4542 - precision_2: 0.9195 - recall_2: 0.2723\n",
      "|| >> End of epoch 45 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8815 - loss: 0.3677 - precision_2: 0.3918 - recall_2: 0.5917 - val_accuracy: 0.8602 - val_loss: 0.3774 - val_precision_2: 1.0000 - val_recall_2: 0.1383\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8630 - loss: 0.3792 - precision_2: 0.9147 - recall_2: 0.2212\n",
      "|| >> End of epoch 46 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8794 - loss: 0.3654 - precision_2: 0.5069 - recall_2: 0.5863 - val_accuracy: 0.8404 - val_loss: 0.4105 - val_precision_2: 1.0000 - val_recall_2: 0.1596\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8528 - loss: 0.3955 - precision_2: 0.9148 - recall_2: 0.2366\n",
      "|| >> End of epoch 47 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8863 - loss: 0.3622 - precision_2: 0.4659 - recall_2: 0.5917 - val_accuracy: 0.8085 - val_loss: 0.4777 - val_precision_2: 1.0000 - val_recall_2: 0.1900\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8152 - loss: 0.4663 - precision_2: 0.9224 - recall_2: 0.2843\n",
      "|| >> End of epoch 48 << ||\n",
      "185/185 - 0s - 3ms/step - accuracy: 0.8897 - loss: 0.3595 - precision_2: 0.5189 - recall_2: 0.5829 - val_accuracy: 0.8100 - val_loss: 0.4723 - val_precision_2: 1.0000 - val_recall_2: 0.1900\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8372 - loss: 0.4200 - precision_2: 0.9200 - recall_2: 0.2565\n",
      "|| >> End of epoch 49 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8846 - loss: 0.3586 - precision_2: 0.4818 - recall_2: 0.5783 - val_accuracy: 0.8754 - val_loss: 0.3751 - val_precision_2: 1.0000 - val_recall_2: 0.1231\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8537 - loss: 0.3998 - precision_2: 0.9134 - recall_2: 0.2381\n",
      "|| >> End of epoch 50 << ||\n",
      "185/185 - 0s - 2ms/step - accuracy: 0.8849 - loss: 0.3603 - precision_2: 0.3985 - recall_2: 0.5863 - val_accuracy: 0.8146 - val_loss: 0.4985 - val_precision_2: 1.0000 - val_recall_2: 0.1839\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8103 - loss: 0.4837 - precision_2: 0.9166 - recall_2: 0.2904\n",
      "|| >> End of epoch 51 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8843 - loss: 0.3662 - precision_2: 0.4560 - recall_2: 0.5790 - val_accuracy: 0.8207 - val_loss: 0.4633 - val_precision_2: 1.0000 - val_recall_2: 0.1793\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8249 - loss: 0.4384 - precision_2: 0.9179 - recall_2: 0.2689\n",
      "|| >> End of epoch 52 << ||\n",
      "185/185 - 0s - 3ms/step - accuracy: 0.8829 - loss: 0.3623 - precision_2: 0.4262 - recall_2: 0.5838 - val_accuracy: 0.8328 - val_loss: 0.4380 - val_precision_2: 1.0000 - val_recall_2: 0.1672\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8269 - loss: 0.4443 - precision_2: 0.9206 - recall_2: 0.2704\n",
      "|| >> End of epoch 53 << ||\n",
      "185/185 - 0s - 3ms/step - accuracy: 0.8886 - loss: 0.3504 - precision_2: 0.4525 - recall_2: 0.5738 - val_accuracy: 0.8161 - val_loss: 0.4677 - val_precision_2: 1.0000 - val_recall_2: 0.1839\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8183 - loss: 0.4614 - precision_2: 0.9208 - recall_2: 0.2810\n",
      "|| >> End of epoch 54 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8868 - loss: 0.3668 - precision_2: 0.4180 - recall_2: 0.5851 - val_accuracy: 0.8100 - val_loss: 0.4886 - val_precision_2: 1.0000 - val_recall_2: 0.1900\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8266 - loss: 0.4493 - precision_2: 0.9187 - recall_2: 0.2712\n",
      "|| >> End of epoch 55 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8853 - loss: 0.3655 - precision_2: 0.4596 - recall_2: 0.5848 - val_accuracy: 0.8359 - val_loss: 0.3871 - val_precision_2: 1.0000 - val_recall_2: 0.1641\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8615 - loss: 0.3731 - precision_2: 0.9150 - recall_2: 0.2238\n",
      "|| >> End of epoch 56 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8924 - loss: 0.3475 - precision_2: 0.4713 - recall_2: 0.5898 - val_accuracy: 0.8450 - val_loss: 0.4121 - val_precision_2: 1.0000 - val_recall_2: 0.1550\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8561 - loss: 0.3935 - precision_2: 0.9137 - recall_2: 0.2335\n",
      "|| >> End of epoch 57 << ||\n",
      "185/185 - 0s - 3ms/step - accuracy: 0.8898 - loss: 0.3587 - precision_2: 0.3685 - recall_2: 0.5777 - val_accuracy: 0.8191 - val_loss: 0.4487 - val_precision_2: 1.0000 - val_recall_2: 0.1809\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8340 - loss: 0.4306 - precision_2: 0.9137 - recall_2: 0.2616\n",
      "|| >> End of epoch 58 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8837 - loss: 0.3661 - precision_2: 0.4504 - recall_2: 0.5733 - val_accuracy: 0.8511 - val_loss: 0.3695 - val_precision_2: 1.0000 - val_recall_2: 0.1474\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8620 - loss: 0.3752 - precision_2: 0.9113 - recall_2: 0.2225\n",
      "|| >> End of epoch 59 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8910 - loss: 0.3542 - precision_2: 0.4406 - recall_2: 0.5892 - val_accuracy: 0.8024 - val_loss: 0.5108 - val_precision_2: 1.0000 - val_recall_2: 0.1976\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8145 - loss: 0.4682 - precision_2: 0.9175 - recall_2: 0.2841\n",
      "|| >> End of epoch 60 << ||\n",
      "185/185 - 1s - 4ms/step - accuracy: 0.8849 - loss: 0.3715 - precision_2: 0.4784 - recall_2: 0.5821 - val_accuracy: 0.8283 - val_loss: 0.4340 - val_precision_2: 1.0000 - val_recall_2: 0.1702\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8392 - loss: 0.4092 - precision_2: 0.9194 - recall_2: 0.2523\n",
      "|| >> End of epoch 61 << ||\n",
      "185/185 - 0s - 3ms/step - accuracy: 0.8870 - loss: 0.3552 - precision_2: 0.4104 - recall_2: 0.5869 - val_accuracy: 0.8678 - val_loss: 0.3476 - val_precision_2: 1.0000 - val_recall_2: 0.1322\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8719 - loss: 0.3616 - precision_2: 0.9116 - recall_2: 0.2071\n",
      "|| >> End of epoch 62 << ||\n",
      "185/185 - 0s - 3ms/step - accuracy: 0.8864 - loss: 0.3575 - precision_2: 0.4475 - recall_2: 0.5776 - val_accuracy: 0.8267 - val_loss: 0.4709 - val_precision_2: 1.0000 - val_recall_2: 0.1733\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8257 - loss: 0.4451 - precision_2: 0.9179 - recall_2: 0.2692\n",
      "|| >> End of epoch 63 << ||\n",
      "185/185 - 0s - 3ms/step - accuracy: 0.8787 - loss: 0.3725 - precision_2: 0.3835 - recall_2: 0.5898 - val_accuracy: 0.8207 - val_loss: 0.4802 - val_precision_2: 1.0000 - val_recall_2: 0.1793\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8318 - loss: 0.4347 - precision_2: 0.9182 - recall_2: 0.2655\n",
      "|| >> End of epoch 64 << ||\n",
      "185/185 - 1s - 4ms/step - accuracy: 0.8880 - loss: 0.3603 - precision_2: 0.4718 - recall_2: 0.5885 - val_accuracy: 0.8116 - val_loss: 0.4646 - val_precision_2: 1.0000 - val_recall_2: 0.1884\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8365 - loss: 0.4347 - precision_2: 0.9168 - recall_2: 0.2578\n",
      "|| >> End of epoch 65 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8839 - loss: 0.3640 - precision_2: 0.3940 - recall_2: 0.5805 - val_accuracy: 0.8343 - val_loss: 0.4134 - val_precision_2: 1.0000 - val_recall_2: 0.1657\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8490 - loss: 0.4102 - precision_2: 0.9143 - recall_2: 0.2407\n",
      "|| >> End of epoch 66 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8870 - loss: 0.3627 - precision_2: 0.4694 - recall_2: 0.5759 - val_accuracy: 0.8465 - val_loss: 0.4151 - val_precision_2: 1.0000 - val_recall_2: 0.1535\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8357 - loss: 0.4311 - precision_2: 0.9167 - recall_2: 0.2561\n",
      "|| >> End of epoch 67 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8890 - loss: 0.3569 - precision_2: 0.4975 - recall_2: 0.5861 - val_accuracy: 0.8571 - val_loss: 0.3785 - val_precision_2: 1.0000 - val_recall_2: 0.1429\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8633 - loss: 0.3760 - precision_2: 0.9138 - recall_2: 0.2213\n",
      "|| >> End of epoch 68 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8812 - loss: 0.3664 - precision_2: 0.4227 - recall_2: 0.5656 - val_accuracy: 0.8267 - val_loss: 0.4376 - val_precision_2: 1.0000 - val_recall_2: 0.1733\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8452 - loss: 0.4050 - precision_2: 0.9169 - recall_2: 0.2457\n",
      "|| >> End of epoch 69 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8871 - loss: 0.3592 - precision_2: 0.4026 - recall_2: 0.5743 - val_accuracy: 0.8465 - val_loss: 0.4324 - val_precision_2: 1.0000 - val_recall_2: 0.1535\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8265 - loss: 0.4452 - precision_2: 0.9185 - recall_2: 0.2667\n",
      "|| >> End of epoch 70 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8863 - loss: 0.3581 - precision_2: 0.4444 - recall_2: 0.5690 - val_accuracy: 0.7933 - val_loss: 0.5234 - val_precision_2: 1.0000 - val_recall_2: 0.2067\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8066 - loss: 0.4903 - precision_2: 0.9200 - recall_2: 0.2956\n",
      "|| >> End of epoch 71 << ||\n",
      "185/185 - 0s - 3ms/step - accuracy: 0.8853 - loss: 0.3656 - precision_2: 0.4210 - recall_2: 0.5926 - val_accuracy: 0.8480 - val_loss: 0.3940 - val_precision_2: 1.0000 - val_recall_2: 0.1520\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8565 - loss: 0.3870 - precision_2: 0.9174 - recall_2: 0.2335\n",
      "|| >> End of epoch 72 << ||\n",
      "185/185 - 0s - 3ms/step - accuracy: 0.8880 - loss: 0.3603 - precision_2: 0.3756 - recall_2: 0.5751 - val_accuracy: 0.7933 - val_loss: 0.5295 - val_precision_2: 1.0000 - val_recall_2: 0.2052\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8174 - loss: 0.4648 - precision_2: 0.9199 - recall_2: 0.2813\n",
      "|| >> End of epoch 73 << ||\n",
      "185/185 - 0s - 3ms/step - accuracy: 0.8878 - loss: 0.3572 - precision_2: 0.4233 - recall_2: 0.5858 - val_accuracy: 0.8328 - val_loss: 0.4690 - val_precision_2: 1.0000 - val_recall_2: 0.1672\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8238 - loss: 0.4602 - precision_2: 0.9171 - recall_2: 0.2719\n",
      "|| >> End of epoch 74 << ||\n",
      "185/185 - 0s - 3ms/step - accuracy: 0.8924 - loss: 0.3493 - precision_2: 0.4286 - recall_2: 0.5713 - val_accuracy: 0.8450 - val_loss: 0.4092 - val_precision_2: 1.0000 - val_recall_2: 0.1550\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8429 - loss: 0.4101 - precision_2: 0.9199 - recall_2: 0.2492\n",
      "|| >> End of epoch 75 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8873 - loss: 0.3633 - precision_2: 0.4902 - recall_2: 0.5860 - val_accuracy: 0.8860 - val_loss: 0.3362 - val_precision_2: 1.0000 - val_recall_2: 0.1140\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8568 - loss: 0.3875 - precision_2: 0.9162 - recall_2: 0.2300\n",
      "|| >> End of epoch 76 << ||\n",
      "185/185 - 1s - 4ms/step - accuracy: 0.8853 - loss: 0.3640 - precision_2: 0.4925 - recall_2: 0.5966 - val_accuracy: 0.8237 - val_loss: 0.4477 - val_precision_2: 1.0000 - val_recall_2: 0.1763\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8392 - loss: 0.4192 - precision_2: 0.9153 - recall_2: 0.2548\n",
      "|| >> End of epoch 77 << ||\n",
      "185/185 - 1s - 4ms/step - accuracy: 0.8831 - loss: 0.3696 - precision_2: 0.4652 - recall_2: 0.5934 - val_accuracy: 0.8480 - val_loss: 0.3854 - val_precision_2: 1.0000 - val_recall_2: 0.1520\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8496 - loss: 0.3965 - precision_2: 0.9136 - recall_2: 0.2433\n",
      "|| >> End of epoch 78 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8892 - loss: 0.3587 - precision_2: 0.4271 - recall_2: 0.5720 - val_accuracy: 0.8389 - val_loss: 0.3939 - val_precision_2: 1.0000 - val_recall_2: 0.1596\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8474 - loss: 0.4009 - precision_2: 0.9170 - recall_2: 0.2416\n",
      "|| >> End of epoch 79 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8812 - loss: 0.3638 - precision_2: 0.4639 - recall_2: 0.6022 - val_accuracy: 0.8298 - val_loss: 0.4434 - val_precision_2: 1.0000 - val_recall_2: 0.1702\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8225 - loss: 0.4453 - precision_2: 0.9190 - recall_2: 0.2728\n",
      "|| >> End of epoch 80 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8844 - loss: 0.3626 - precision_2: 0.4965 - recall_2: 0.5915 - val_accuracy: 0.8191 - val_loss: 0.4589 - val_precision_2: 1.0000 - val_recall_2: 0.1809\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8210 - loss: 0.4482 - precision_2: 0.9172 - recall_2: 0.2749\n",
      "|| >> End of epoch 81 << ||\n",
      "185/185 - 1s - 4ms/step - accuracy: 0.8897 - loss: 0.3569 - precision_2: 0.4167 - recall_2: 0.5804 - val_accuracy: 0.8161 - val_loss: 0.4537 - val_precision_2: 1.0000 - val_recall_2: 0.1839\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8392 - loss: 0.4117 - precision_2: 0.9179 - recall_2: 0.2545\n",
      "|| >> End of epoch 82 << ||\n",
      "185/185 - 1s - 4ms/step - accuracy: 0.8900 - loss: 0.3579 - precision_2: 0.3830 - recall_2: 0.5788 - val_accuracy: 0.8404 - val_loss: 0.3941 - val_precision_2: 1.0000 - val_recall_2: 0.1596\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8522 - loss: 0.3922 - precision_2: 0.9163 - recall_2: 0.2345\n",
      "|| >> End of epoch 83 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8893 - loss: 0.3561 - precision_2: 0.4411 - recall_2: 0.5855 - val_accuracy: 0.8465 - val_loss: 0.4103 - val_precision_2: 1.0000 - val_recall_2: 0.1535\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8522 - loss: 0.4034 - precision_2: 0.9169 - recall_2: 0.2372\n",
      "|| >> End of epoch 84 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8805 - loss: 0.3717 - precision_2: 0.4861 - recall_2: 0.5859 - val_accuracy: 0.8632 - val_loss: 0.3745 - val_precision_2: 1.0000 - val_recall_2: 0.1368\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8542 - loss: 0.3936 - precision_2: 0.9161 - recall_2: 0.2342\n",
      "|| >> End of epoch 85 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8892 - loss: 0.3503 - precision_2: 0.4382 - recall_2: 0.5733 - val_accuracy: 0.8085 - val_loss: 0.4831 - val_precision_2: 1.0000 - val_recall_2: 0.1915\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8198 - loss: 0.4624 - precision_2: 0.9194 - recall_2: 0.2802\n",
      "|| >> End of epoch 86 << ||\n",
      "185/185 - 1s - 4ms/step - accuracy: 0.8868 - loss: 0.3631 - precision_2: 0.4020 - recall_2: 0.5913 - val_accuracy: 0.8465 - val_loss: 0.3977 - val_precision_2: 1.0000 - val_recall_2: 0.1535\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8544 - loss: 0.3901 - precision_2: 0.9147 - recall_2: 0.2351\n",
      "|| >> End of epoch 87 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8809 - loss: 0.3656 - precision_2: 0.4100 - recall_2: 0.5910 - val_accuracy: 0.7736 - val_loss: 0.5320 - val_precision_2: 1.0000 - val_recall_2: 0.2264\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8056 - loss: 0.4856 - precision_2: 0.9211 - recall_2: 0.2979\n",
      "|| >> End of epoch 88 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8827 - loss: 0.3663 - precision_2: 0.4080 - recall_2: 0.5869 - val_accuracy: 0.8313 - val_loss: 0.4282 - val_precision_2: 1.0000 - val_recall_2: 0.1687\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8341 - loss: 0.4284 - precision_2: 0.9160 - recall_2: 0.2584\n",
      "|| >> End of epoch 89 << ||\n",
      "185/185 - 1s - 4ms/step - accuracy: 0.8787 - loss: 0.3739 - precision_2: 0.4554 - recall_2: 0.5975 - val_accuracy: 0.8465 - val_loss: 0.4224 - val_precision_2: 1.0000 - val_recall_2: 0.1535\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8312 - loss: 0.4224 - precision_2: 0.9161 - recall_2: 0.2650\n",
      "|| >> End of epoch 90 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8822 - loss: 0.3660 - precision_2: 0.3778 - recall_2: 0.5947 - val_accuracy: 0.8723 - val_loss: 0.3654 - val_precision_2: 1.0000 - val_recall_2: 0.1277\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8598 - loss: 0.3757 - precision_2: 0.9170 - recall_2: 0.2239\n",
      "|| >> End of epoch 91 << ||\n",
      "185/185 - 1s - 4ms/step - accuracy: 0.8910 - loss: 0.3520 - precision_2: 0.3319 - recall_2: 0.5616 - val_accuracy: 0.8252 - val_loss: 0.4814 - val_precision_2: 1.0000 - val_recall_2: 0.1748\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8155 - loss: 0.4684 - precision_2: 0.9154 - recall_2: 0.2847\n",
      "|| >> End of epoch 92 << ||\n",
      "185/185 - 1s - 4ms/step - accuracy: 0.8841 - loss: 0.3625 - precision_2: 0.4786 - recall_2: 0.5838 - val_accuracy: 0.8252 - val_loss: 0.4334 - val_precision_2: 1.0000 - val_recall_2: 0.1748\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8264 - loss: 0.4358 - precision_2: 0.9212 - recall_2: 0.2721\n",
      "|| >> End of epoch 93 << ||\n",
      "185/185 - 1s - 4ms/step - accuracy: 0.8890 - loss: 0.3611 - precision_2: 0.4152 - recall_2: 0.5843 - val_accuracy: 0.8298 - val_loss: 0.4345 - val_precision_2: 1.0000 - val_recall_2: 0.1702\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8278 - loss: 0.4424 - precision_2: 0.9191 - recall_2: 0.2678\n",
      "|| >> End of epoch 94 << ||\n",
      "185/185 - 1s - 4ms/step - accuracy: 0.8856 - loss: 0.3663 - precision_2: 0.3820 - recall_2: 0.5788 - val_accuracy: 0.8313 - val_loss: 0.4353 - val_precision_2: 1.0000 - val_recall_2: 0.1687\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8289 - loss: 0.4328 - precision_2: 0.9185 - recall_2: 0.2670\n",
      "|| >> End of epoch 95 << ||\n",
      "185/185 - 1s - 4ms/step - accuracy: 0.8821 - loss: 0.3635 - precision_2: 0.4727 - recall_2: 0.5959 - val_accuracy: 0.8328 - val_loss: 0.4668 - val_precision_2: 1.0000 - val_recall_2: 0.1672\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8395 - loss: 0.4202 - precision_2: 0.9165 - recall_2: 0.2550\n",
      "|| >> End of epoch 96 << ||\n",
      "185/185 - 1s - 4ms/step - accuracy: 0.8794 - loss: 0.3702 - precision_2: 0.4550 - recall_2: 0.5812 - val_accuracy: 0.8343 - val_loss: 0.4535 - val_precision_2: 1.0000 - val_recall_2: 0.1657\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8277 - loss: 0.4346 - precision_2: 0.9186 - recall_2: 0.2673\n",
      "|| >> End of epoch 97 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8871 - loss: 0.3606 - precision_2: 0.4560 - recall_2: 0.5945 - val_accuracy: 0.8222 - val_loss: 0.4555 - val_precision_2: 1.0000 - val_recall_2: 0.1778\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8401 - loss: 0.4145 - precision_2: 0.9206 - recall_2: 0.2517\n",
      "|| >> End of epoch 98 << ||\n",
      "185/185 - 1s - 4ms/step - accuracy: 0.8856 - loss: 0.3611 - precision_2: 0.4555 - recall_2: 0.5794 - val_accuracy: 0.7888 - val_loss: 0.4990 - val_precision_2: 1.0000 - val_recall_2: 0.2112\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8181 - loss: 0.4699 - precision_2: 0.9196 - recall_2: 0.2816\n",
      "|| >> End of epoch 99 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8947 - loss: 0.3518 - precision_2: 0.4980 - recall_2: 0.5853 - val_accuracy: 0.8267 - val_loss: 0.4587 - val_precision_2: 1.0000 - val_recall_2: 0.1733\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8468 - loss: 0.4032 - precision_2: 0.9133 - recall_2: 0.2448\n",
      "|| >> End of epoch 100 << ||\n",
      "185/185 - 1s - 4ms/step - accuracy: 0.8876 - loss: 0.3538 - precision_2: 0.4395 - recall_2: 0.5794 - val_accuracy: 0.8541 - val_loss: 0.3766 - val_precision_2: 1.0000 - val_recall_2: 0.1459\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8666 - loss: 0.3680 - precision_2: 0.9100 - recall_2: 0.2156\n",
      "|| >> End of epoch 101 << ||\n",
      "185/185 - 1s - 4ms/step - accuracy: 0.8836 - loss: 0.3713 - precision_2: 0.4697 - recall_2: 0.5952 - val_accuracy: 0.8267 - val_loss: 0.4481 - val_precision_2: 1.0000 - val_recall_2: 0.1733\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8072 - loss: 0.4878 - precision_2: 0.9186 - recall_2: 0.2965\n",
      "|| >> End of epoch 102 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8809 - loss: 0.3682 - precision_2: 0.4085 - recall_2: 0.5793 - val_accuracy: 0.8116 - val_loss: 0.4856 - val_precision_2: 1.0000 - val_recall_2: 0.1884\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8302 - loss: 0.4312 - precision_2: 0.9196 - recall_2: 0.2662\n",
      "|| >> End of epoch 103 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8881 - loss: 0.3599 - precision_2: 0.4117 - recall_2: 0.5821 - val_accuracy: 0.8359 - val_loss: 0.4108 - val_precision_2: 1.0000 - val_recall_2: 0.1641\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8371 - loss: 0.4148 - precision_2: 0.9176 - recall_2: 0.2568\n",
      "|| >> End of epoch 104 << ||\n",
      "185/185 - 1s - 4ms/step - accuracy: 0.8864 - loss: 0.3603 - precision_2: 0.4541 - recall_2: 0.5847 - val_accuracy: 0.8647 - val_loss: 0.3663 - val_precision_2: 1.0000 - val_recall_2: 0.1337\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8526 - loss: 0.3968 - precision_2: 0.9151 - recall_2: 0.2369\n",
      "|| >> End of epoch 105 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8807 - loss: 0.3726 - precision_2: 0.3839 - recall_2: 0.5757 - val_accuracy: 0.8313 - val_loss: 0.4544 - val_precision_2: 1.0000 - val_recall_2: 0.1687\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8561 - loss: 0.3954 - precision_2: 0.9160 - recall_2: 0.2350\n",
      "|| >> End of epoch 106 << ||\n",
      "185/185 - 1s - 4ms/step - accuracy: 0.8834 - loss: 0.3707 - precision_2: 0.4465 - recall_2: 0.5827 - val_accuracy: 0.8419 - val_loss: 0.4134 - val_precision_2: 1.0000 - val_recall_2: 0.1581\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8358 - loss: 0.4228 - precision_2: 0.9161 - recall_2: 0.2576\n",
      "|| >> End of epoch 107 << ||\n",
      "185/185 - 1s - 4ms/step - accuracy: 0.8856 - loss: 0.3655 - precision_2: 0.4473 - recall_2: 0.5770 - val_accuracy: 0.8207 - val_loss: 0.4584 - val_precision_2: 1.0000 - val_recall_2: 0.1778\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8200 - loss: 0.4516 - precision_2: 0.9201 - recall_2: 0.2781\n",
      "|| >> End of epoch 108 << ||\n",
      "185/185 - 1s - 4ms/step - accuracy: 0.8859 - loss: 0.3638 - precision_2: 0.4091 - recall_2: 0.5930 - val_accuracy: 0.8526 - val_loss: 0.4015 - val_precision_2: 1.0000 - val_recall_2: 0.1474\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8580 - loss: 0.3906 - precision_2: 0.9107 - recall_2: 0.2311\n",
      "|| >> End of epoch 109 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8864 - loss: 0.3583 - precision_2: 0.4715 - recall_2: 0.5846 - val_accuracy: 0.8571 - val_loss: 0.3777 - val_precision_2: 1.0000 - val_recall_2: 0.1429\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8598 - loss: 0.3825 - precision_2: 0.9122 - recall_2: 0.2284\n",
      "|| >> End of epoch 110 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8890 - loss: 0.3610 - precision_2: 0.4416 - recall_2: 0.5815 - val_accuracy: 0.8116 - val_loss: 0.4625 - val_precision_2: 1.0000 - val_recall_2: 0.1884\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8172 - loss: 0.4553 - precision_2: 0.9181 - recall_2: 0.2821\n",
      "|| >> End of epoch 111 << ||\n",
      "185/185 - 1s - 4ms/step - accuracy: 0.8875 - loss: 0.3550 - precision_2: 0.4665 - recall_2: 0.5801 - val_accuracy: 0.7979 - val_loss: 0.4958 - val_precision_2: 1.0000 - val_recall_2: 0.2021\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8189 - loss: 0.4377 - precision_2: 0.9187 - recall_2: 0.2762\n",
      "|| >> End of epoch 112 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8841 - loss: 0.3634 - precision_2: 0.4118 - recall_2: 0.5656 - val_accuracy: 0.8085 - val_loss: 0.4768 - val_precision_2: 1.0000 - val_recall_2: 0.1900\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8277 - loss: 0.4379 - precision_2: 0.9220 - recall_2: 0.2715\n",
      "|| >> End of epoch 113 << ||\n",
      "185/185 - 1s - 4ms/step - accuracy: 0.8939 - loss: 0.3498 - precision_2: 0.3856 - recall_2: 0.5739 - val_accuracy: 0.8343 - val_loss: 0.4459 - val_precision_2: 1.0000 - val_recall_2: 0.1657\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8348 - loss: 0.4304 - precision_2: 0.9194 - recall_2: 0.2610\n",
      "|| >> End of epoch 114 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8868 - loss: 0.3601 - precision_2: 0.4335 - recall_2: 0.5907 - val_accuracy: 0.7827 - val_loss: 0.5217 - val_precision_2: 1.0000 - val_recall_2: 0.2173\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8191 - loss: 0.4554 - precision_2: 0.9192 - recall_2: 0.2792\n",
      "|| >> End of epoch 115 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8929 - loss: 0.3508 - precision_2: 0.4107 - recall_2: 0.5906 - val_accuracy: 0.8602 - val_loss: 0.3795 - val_precision_2: 1.0000 - val_recall_2: 0.1398\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8525 - loss: 0.3939 - precision_2: 0.9143 - recall_2: 0.2366\n",
      "|| >> End of epoch 116 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8875 - loss: 0.3562 - precision_2: 0.4349 - recall_2: 0.5907 - val_accuracy: 0.8237 - val_loss: 0.4281 - val_precision_2: 1.0000 - val_recall_2: 0.1763\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8552 - loss: 0.3962 - precision_2: 0.9154 - recall_2: 0.2348\n",
      "|| >> End of epoch 117 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8782 - loss: 0.3744 - precision_2: 0.4254 - recall_2: 0.5860 - val_accuracy: 0.8480 - val_loss: 0.4298 - val_precision_2: 1.0000 - val_recall_2: 0.1520\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8410 - loss: 0.4063 - precision_2: 0.9169 - recall_2: 0.2523\n",
      "|| >> End of epoch 118 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8861 - loss: 0.3634 - precision_2: 0.4349 - recall_2: 0.5938 - val_accuracy: 0.8511 - val_loss: 0.3974 - val_precision_2: 1.0000 - val_recall_2: 0.1489\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8475 - loss: 0.3962 - precision_2: 0.9179 - recall_2: 0.2429\n",
      "|| >> End of epoch 119 << ||\n",
      "185/185 - 0s - 2ms/step - accuracy: 0.8836 - loss: 0.3653 - precision_2: 0.4506 - recall_2: 0.5923 - val_accuracy: 0.8511 - val_loss: 0.3993 - val_precision_2: 1.0000 - val_recall_2: 0.1489\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8476 - loss: 0.3996 - precision_2: 0.9139 - recall_2: 0.2422\n",
      "|| >> End of epoch 120 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8804 - loss: 0.3655 - precision_2: 0.4930 - recall_2: 0.5962 - val_accuracy: 0.7812 - val_loss: 0.5245 - val_precision_2: 1.0000 - val_recall_2: 0.2188\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8134 - loss: 0.4775 - precision_2: 0.9161 - recall_2: 0.2873\n",
      "|| >> End of epoch 121 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8812 - loss: 0.3570 - precision_2: 0.4336 - recall_2: 0.5938 - val_accuracy: 0.8222 - val_loss: 0.4528 - val_precision_2: 1.0000 - val_recall_2: 0.1778\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8224 - loss: 0.4467 - precision_2: 0.9193 - recall_2: 0.2752\n",
      "|| >> End of epoch 122 << ||\n",
      "185/185 - 1s - 4ms/step - accuracy: 0.8881 - loss: 0.3563 - precision_2: 0.4306 - recall_2: 0.5820 - val_accuracy: 0.8495 - val_loss: 0.3853 - val_precision_2: 1.0000 - val_recall_2: 0.1505\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8596 - loss: 0.3857 - precision_2: 0.9173 - recall_2: 0.2298\n",
      "|| >> End of epoch 123 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8890 - loss: 0.3594 - precision_2: 0.5027 - recall_2: 0.5849 - val_accuracy: 0.8343 - val_loss: 0.4287 - val_precision_2: 1.0000 - val_recall_2: 0.1657\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8212 - loss: 0.4529 - precision_2: 0.9185 - recall_2: 0.2746\n",
      "|| >> End of epoch 124 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8829 - loss: 0.3683 - precision_2: 0.4569 - recall_2: 0.6012 - val_accuracy: 0.8161 - val_loss: 0.4600 - val_precision_2: 1.0000 - val_recall_2: 0.1839\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8226 - loss: 0.4425 - precision_2: 0.9187 - recall_2: 0.2758\n",
      "|| >> End of epoch 125 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8905 - loss: 0.3528 - precision_2: 0.4502 - recall_2: 0.5752 - val_accuracy: 0.8252 - val_loss: 0.4518 - val_precision_2: 1.0000 - val_recall_2: 0.1748\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8283 - loss: 0.4469 - precision_2: 0.9194 - recall_2: 0.2689\n",
      "|| >> End of epoch 126 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8841 - loss: 0.3612 - precision_2: 0.4217 - recall_2: 0.5887 - val_accuracy: 0.8222 - val_loss: 0.4696 - val_precision_2: 1.0000 - val_recall_2: 0.1778\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8354 - loss: 0.4238 - precision_2: 0.9167 - recall_2: 0.2596\n",
      "|| >> End of epoch 127 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8905 - loss: 0.3561 - precision_2: 0.4418 - recall_2: 0.5822 - val_accuracy: 0.8526 - val_loss: 0.3774 - val_precision_2: 1.0000 - val_recall_2: 0.1474\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8551 - loss: 0.3962 - precision_2: 0.9137 - recall_2: 0.2341\n",
      "|| >> End of epoch 128 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8892 - loss: 0.3573 - precision_2: 0.4492 - recall_2: 0.5874 - val_accuracy: 0.7872 - val_loss: 0.5504 - val_precision_2: 1.0000 - val_recall_2: 0.2128\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8000 - loss: 0.5084 - precision_2: 0.9172 - recall_2: 0.3022\n",
      "|| >> End of epoch 129 << ||\n",
      "185/185 - 1s - 4ms/step - accuracy: 0.8924 - loss: 0.3460 - precision_2: 0.4990 - recall_2: 0.5855 - val_accuracy: 0.8343 - val_loss: 0.4399 - val_precision_2: 1.0000 - val_recall_2: 0.1657\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8384 - loss: 0.4175 - precision_2: 0.9215 - recall_2: 0.2521\n",
      "|| >> End of epoch 130 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8864 - loss: 0.3620 - precision_2: 0.4432 - recall_2: 0.5812 - val_accuracy: 0.8465 - val_loss: 0.4250 - val_precision_2: 1.0000 - val_recall_2: 0.1535\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8343 - loss: 0.4206 - precision_2: 0.9186 - recall_2: 0.2584\n",
      "|| >> End of epoch 131 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8922 - loss: 0.3546 - precision_2: 0.3917 - recall_2: 0.5701 - val_accuracy: 0.8085 - val_loss: 0.4565 - val_precision_2: 1.0000 - val_recall_2: 0.1915\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8319 - loss: 0.4359 - precision_2: 0.9151 - recall_2: 0.2626\n",
      "|| >> End of epoch 132 << ||\n",
      "185/185 - 1s - 4ms/step - accuracy: 0.8859 - loss: 0.3620 - precision_2: 0.4040 - recall_2: 0.5938 - val_accuracy: 0.8176 - val_loss: 0.4484 - val_precision_2: 1.0000 - val_recall_2: 0.1824\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8227 - loss: 0.4454 - precision_2: 0.9188 - recall_2: 0.2754\n",
      "|| >> End of epoch 133 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8851 - loss: 0.3620 - precision_2: 0.4164 - recall_2: 0.5738 - val_accuracy: 0.8313 - val_loss: 0.4325 - val_precision_2: 1.0000 - val_recall_2: 0.1687\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8195 - loss: 0.4489 - precision_2: 0.9193 - recall_2: 0.2799\n",
      "|| >> End of epoch 134 << ||\n",
      "185/185 - 1s - 4ms/step - accuracy: 0.8797 - loss: 0.3697 - precision_2: 0.4310 - recall_2: 0.5828 - val_accuracy: 0.8495 - val_loss: 0.3890 - val_precision_2: 1.0000 - val_recall_2: 0.1505\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8236 - loss: 0.4337 - precision_2: 0.9203 - recall_2: 0.2730\n",
      "|| >> End of epoch 135 << ||\n",
      "185/185 - 1s - 4ms/step - accuracy: 0.8836 - loss: 0.3736 - precision_2: 0.4656 - recall_2: 0.5892 - val_accuracy: 0.8495 - val_loss: 0.4155 - val_precision_2: 1.0000 - val_recall_2: 0.1505\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8375 - loss: 0.4150 - precision_2: 0.9205 - recall_2: 0.2586\n",
      "|| >> End of epoch 136 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8917 - loss: 0.3554 - precision_2: 0.4355 - recall_2: 0.5812 - val_accuracy: 0.8343 - val_loss: 0.4265 - val_precision_2: 1.0000 - val_recall_2: 0.1657\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8410 - loss: 0.4227 - precision_2: 0.9145 - recall_2: 0.2533\n",
      "|| >> End of epoch 137 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8895 - loss: 0.3616 - precision_2: 0.4694 - recall_2: 0.5815 - val_accuracy: 0.8465 - val_loss: 0.3936 - val_precision_2: 1.0000 - val_recall_2: 0.1535\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8347 - loss: 0.4162 - precision_2: 0.9145 - recall_2: 0.2573\n",
      "|| >> End of epoch 138 << ||\n",
      "185/185 - 1s - 4ms/step - accuracy: 0.8885 - loss: 0.3551 - precision_2: 0.3706 - recall_2: 0.5862 - val_accuracy: 0.8116 - val_loss: 0.4634 - val_precision_2: 1.0000 - val_recall_2: 0.1884\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8333 - loss: 0.4360 - precision_2: 0.9183 - recall_2: 0.2611\n",
      "|| >> End of epoch 139 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8873 - loss: 0.3654 - precision_2: 0.4588 - recall_2: 0.5805 - val_accuracy: 0.8389 - val_loss: 0.4198 - val_precision_2: 1.0000 - val_recall_2: 0.1611\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8534 - loss: 0.3905 - precision_2: 0.9148 - recall_2: 0.2376\n",
      "|| >> End of epoch 140 << ||\n",
      "185/185 - 1s - 4ms/step - accuracy: 0.8824 - loss: 0.3610 - precision_2: 0.4624 - recall_2: 0.5771 - val_accuracy: 0.8283 - val_loss: 0.4453 - val_precision_2: 1.0000 - val_recall_2: 0.1717\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8271 - loss: 0.4483 - precision_2: 0.9191 - recall_2: 0.2687\n",
      "|| >> End of epoch 141 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8880 - loss: 0.3685 - precision_2: 0.4476 - recall_2: 0.5905 - val_accuracy: 0.8267 - val_loss: 0.4559 - val_precision_2: 1.0000 - val_recall_2: 0.1733\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8349 - loss: 0.4190 - precision_2: 0.9169 - recall_2: 0.2600\n",
      "|| >> End of epoch 142 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8859 - loss: 0.3628 - precision_2: 0.4820 - recall_2: 0.5775 - val_accuracy: 0.8207 - val_loss: 0.4848 - val_precision_2: 1.0000 - val_recall_2: 0.1793\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8208 - loss: 0.4509 - precision_2: 0.9189 - recall_2: 0.2770\n",
      "|| >> End of epoch 143 << ||\n",
      "185/185 - 1s - 4ms/step - accuracy: 0.8810 - loss: 0.3673 - precision_2: 0.4465 - recall_2: 0.5794 - val_accuracy: 0.7948 - val_loss: 0.4712 - val_precision_2: 1.0000 - val_recall_2: 0.2052\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8372 - loss: 0.4198 - precision_2: 0.9159 - recall_2: 0.2569\n",
      "|| >> End of epoch 144 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8890 - loss: 0.3541 - precision_2: 0.4541 - recall_2: 0.5883 - val_accuracy: 0.8131 - val_loss: 0.4641 - val_precision_2: 1.0000 - val_recall_2: 0.1869\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8348 - loss: 0.4331 - precision_2: 0.9192 - recall_2: 0.2603\n",
      "|| >> End of epoch 145 << ||\n",
      "185/185 - 1s - 3ms/step - accuracy: 0.8885 - loss: 0.3637 - precision_2: 0.4758 - recall_2: 0.5942 - val_accuracy: 0.8116 - val_loss: 0.4665 - val_precision_2: 1.0000 - val_recall_2: 0.1884\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8187 - loss: 0.4502 - precision_2: 0.9148 - recall_2: 0.2796\n",
      "|| >> End of epoch 146 << ||\n",
      "185/185 - 1s - 4ms/step - accuracy: 0.8851 - loss: 0.3626 - precision_2: 0.4402 - recall_2: 0.5923 - val_accuracy: 0.8647 - val_loss: 0.3773 - val_precision_2: 1.0000 - val_recall_2: 0.1353\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8577 - loss: 0.3875 - precision_2: 0.9121 - recall_2: 0.2330\n",
      "|| >> End of epoch 147 << ||\n",
      "185/185 - 1s - 4ms/step - accuracy: 0.8856 - loss: 0.3616 - precision_2: 0.4548 - recall_2: 0.5828 - val_accuracy: 0.8070 - val_loss: 0.4856 - val_precision_2: 1.0000 - val_recall_2: 0.1930\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8172 - loss: 0.4479 - precision_2: 0.9191 - recall_2: 0.2784\n",
      "|| >> End of epoch 148 << ||\n",
      "185/185 - 1s - 4ms/step - accuracy: 0.8908 - loss: 0.3544 - precision_2: 0.5028 - recall_2: 0.5788 - val_accuracy: 0.8283 - val_loss: 0.4407 - val_precision_2: 1.0000 - val_recall_2: 0.1717\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8262 - loss: 0.4419 - precision_2: 0.9190 - recall_2: 0.2683\n",
      "|| >> End of epoch 149 << ||\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "num_of_epochs = 150\n",
    "model_name = \"NN_balanced_1\"\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1) \n",
    "\n",
    "X_class_0 = X_train[ Y_train == 0 ]\n",
    "Y_class_0 = Y_train[ Y_train == 0 ]\n",
    "\n",
    "num_of_class_0 = len(Y_class_0)\n",
    "\n",
    "XY = np.concatenate((X, Y.reshape(-1,1)), axis=1)\n",
    "\n",
    "best_loss = 1000000\n",
    "best_epoch = 0\n",
    "os.makedirs(f'../mount/trained_models/{model_name}', exist_ok=True)\n",
    "\n",
    "for i in range(num_of_epochs):\n",
    "    XY = XY[ XY[:, -1] == 1 ]\n",
    "    XY_sels = np.random.choice(XY.shape[0], num_of_class_0)\n",
    "    XY_class_1 = XY[ XY_sels ]\n",
    "    X_class_1 = XY_class_1[:, :-1]\n",
    "    Y_class_1 = XY_class_1[:, -1]\n",
    "    X_batch = np.concatenate((X_class_0, X_class_1), axis=0)\n",
    "    Y_batch = np.concatenate((Y_class_0, Y_class_1), axis=0)\n",
    "    model.fit(X_batch, \n",
    "              Y_batch, \n",
    "              epochs=1, \n",
    "              validation_split=0.1,\n",
    "              verbose=2)\n",
    "    val_loss, val_acc, val_prec, val_recall = model.evaluate(X_test, Y_test)\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        best_epoch = i\n",
    "        model.save(f'../mount/trained_models/{model_name}/best_model.keras')\n",
    "    print(f\"|| >> End of epoch {i} << ||\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best loss: 0.35168182849884033 at epoch 62\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best loss: {best_loss} at epoch {best_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "||>> Precision:  0.46714285714285714\n",
      "||>> Recall:  0.8605263157894737\n",
      "||>> F1:  0.6055555555555555\n",
      "||>> Accuracy:  0.8706739526411658\n",
      "||>> AUC:  0.9397617671495141\n",
      "||>> AUPRC:  0.6800074381392581\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_dir = os.path.join('../mount/trained_models', model_name)\n",
    "\n",
    "best_model = tf.keras.models.load_model(os.path.join(model_dir, 'best_model.keras'))\n",
    "\n",
    "Y_prob = best_model.predict(X_test)\n",
    "Y_pred = np.argmax(Y_prob, axis=1)\n",
    "\n",
    "precision, recall, f1, accuracy, AUC, AUPRC = evaluation_metrics(Y_test, Y_pred, Y_prob, save_plots_dir=model_dir)\n",
    "with open(os.path.join(model_dir, 'metrics.txt'), 'w') as f:\n",
    "    f.write(\"Precision: {}\\n\".format(precision))\n",
    "    f.write(\"Recall: {}\\n\".format(recall))\n",
    "    f.write(\"F1: {}\\n\".format(f1))\n",
    "    f.write(\"Accuracy: {}\\n\".format(accuracy))\n",
    "    f.write(\"AUC: {}\\n\".format(AUC))\n",
    "    f.write(\"AUPRC: {}\\n\".format(AUPRC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
